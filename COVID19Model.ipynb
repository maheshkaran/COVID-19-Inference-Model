{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The COVID-19 Model\n",
    "\n",
    "According to the method outlined in the paper \"Inferring change points in the spread of COVID-19 reveals the effectivencess of interventions\" by Dehning, Zierenberg, et. al., we use assume a standard SIR model with a new equation that accounts for the delay between _true_ infections at time _t_ and _reported_ infections at time _t_ (which we will call the reporting delay _D_) and the sinusoidal modulation of cases over a given week. In the following implementation, we only consider a stationary infection rate.\n",
    "\n",
    "We implement the PINTS model below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir(\"../pints\")\n",
    "\n",
    "import pints\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import math\n",
    "from scipy.stats import vonmises\n",
    "\n",
    "class covidInferenceModel (pints.ForwardModel):\n",
    "    \n",
    "    def simulate(self, parameters, times):\n",
    "\n",
    "        \n",
    "        def SIRDiffEq (y, t, N, lam, mu):\n",
    "            #This equation describes the differential equations of the SIR model and takes in parameters:\n",
    "                #N: population size\n",
    "                #lam: lambda, the rate of disease spread\n",
    "                #mu: rate at which infected persons recover\n",
    "            \n",
    "            S, I, R = y\n",
    "            \n",
    "            dSdt = -lam * S * I / N\n",
    "            dIdt = (lam * S * I / N) - (mu * I)\n",
    "            dRdt = mu * I\n",
    "            \n",
    "            return dSdt, dIdt, dRdt\n",
    "        \n",
    "        def newReportedCasesEqn (t, period, f_w, phi_w, delay, I0, N, lam, mu):\n",
    "            #delay between new infections and new cases of infections reported with parameters:\n",
    "                #t: array of times\n",
    "                #f_w: weekly modulation amplitude\n",
    "                #phi_w: weekly modulation phase\n",
    "                #delay: time it takes to report cases (initial cases reported when t>D)\n",
    "                #I0: number of initally infected at t=0\n",
    "                #N: population size\n",
    "                #lam: lambda, the rate of disease spread\n",
    "                #mu: rate at which infected persons recover\n",
    "                     \n",
    "            \n",
    "            #at t=0, finding infected and recovered populations, initially recovered is 0\n",
    "            casesArray = odeint(SIRDiffEq, [S0,I0,0], t, args=(N, lam, mu))\n",
    "            infectedArray = np.array(casesArray[1])\n",
    "            recoveredArray = np.array(casesArray[2])\n",
    "            \n",
    "            newInfectedCases = np.diff(infectedArray)   \n",
    "        \n",
    "    def n_parameters(self):\n",
    "        return 6\n",
    "    \n",
    "covidModel = covidInferenceModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve the data from the JHU repository over the selected time interval and construct a single output problem in PINTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a1bc8a76c297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#insert data retrieval method here and give array of times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingleOutputProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovidModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'times' is not defined"
     ]
    }
   ],
   "source": [
    "#insert data retrieval method here and give array of times\n",
    "\n",
    "times = [0,0]\n",
    "\n",
    "problem = pints.SingleOutputProblem(covidModel, times, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following list of parameters to be estimated:\n",
    "$$\n",
    "\\theta = [ \\lambda, \\mu, D, I_0, f_w, \\phi_w,\\sigma]\n",
    "$$\n",
    "\n",
    "where \\\\(\\sigma \\\\) is the scale width factor to the likelihood distribution. Below, we describe the likelihood for the data given the parameters, \\\\(p(\\hat C| \\theta)\\\\), as a Student-T distribution with 4 degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'problem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e64d6729bd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m         )\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mlikelhood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStudentTLogLikelihoodMultiplicative4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'problem' is not defined"
     ]
    }
   ],
   "source": [
    "class StudentTLogLikelihoodMultiplicative(pints.ProblemLogLikelihood):\n",
    "    r\"\"\"\n",
    "    Calculates a log-likelihood assuming independent Student-t-distributed\n",
    "    noise at each time point, and adds two parameters: one representing the\n",
    "    degrees of freedom (``nu``), the other representing the scale (``sigma``).\n",
    "\n",
    "    For a noise characterised by ``nu'' and ``sigma``, the log likelihood is of\n",
    "    the form:\n",
    "\n",
    "    .. math::\n",
    "        \\log{L(\\theta, \\nu, \\sigma|\\boldsymbol{x})} =\n",
    "            N\\frac{\\nu}{2}\\log(\\nu) - N\\log(\\sigma\\sqrt{f(\\theta)}) -\n",
    "            N\\log B(\\nu/2, 1/2)\n",
    "            -\\frac{1+\\nu}{2}\\sum_{i=1}^N\\log(\\nu +\n",
    "            \\frac{x_i - f(\\theta)}{\\sigma\\sqrt{f(\\theta)}}^2)\n",
    "\n",
    "    where ``B(.,.)`` is a beta function.\n",
    "\n",
    "    Extends :class:`ProblemLogLikelihood`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem\n",
    "        A :class:`SingleOutputProblem` or :class:`MultiOutputProblem`. For a\n",
    "        single-output problem two parameters are added ``(nu, sigma)``, where\n",
    "        ``nu`` is the degrees of freedom and ``sigma`` is scale, for a\n",
    "        multi-output problem ``2 * n_outputs`` parameters are added.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, problem):\n",
    "        super(StudentTLogLikelihoodMultiplicative, self).__init__(problem)\n",
    "\n",
    "        # Get number of times, number of outputs\n",
    "        self._nt = len(self._times)\n",
    "        self._no = problem.n_outputs()\n",
    "\n",
    "        # Add parameters to problem (two for each output)\n",
    "        self._n_parameters = problem.n_parameters() + 2 * self._no\n",
    "\n",
    "        # Pre-calculate\n",
    "        self._n = len(self._times)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # For multiparameter problems the parameters are stored as\n",
    "        # (model_params_1, model_params_2, ..., model_params_k,\n",
    "        # nu_1, sigma_1, nu_2, sigma_2,...)\n",
    "        n = self._n\n",
    "        m = 2 * self._no\n",
    "\n",
    "        # problem parameters\n",
    "        problem_parameters = x[:-m]\n",
    "        y = self._problem.evaluate(problem_parameters)\n",
    "        error = self._values - y\n",
    "\n",
    "        # Distribution parameters\n",
    "        parameters = x[-m:]\n",
    "        nu = np.asarray(parameters[0::2])\n",
    "        sigma = np.asarray(parameters[1::2])\n",
    "\n",
    "        # Calculate\n",
    "        return np.sum(\n",
    "            + 0.5 * n * nu * np.log(nu)\n",
    "            - n * np.log(sigma * np.sqrt(y))\n",
    "            - n * np.log(scipy.special.beta(0.5 * nu, 0.5))\n",
    "            - 0.5 * (1 + nu) * np.sum(np.log(nu + (error / (sigma * sqrt(y)))**2), axis=0)\n",
    "        )\n",
    "\n",
    "class StudentTLogLikelihoodMultiplicative4(pints.ProblemLogLikelihood):\n",
    "    r\"\"\"\n",
    "    Calculates a log-likelihood assuming independent Student-t-distributed\n",
    "    noise at each time point, and adds two parameters: one representing the\n",
    "    degrees of freedom (``nu``), the other representing the scale (``sigma``).\n",
    "\n",
    "    For a noise characterised by ``nu'' and ``sigma``, the log likelihood is of\n",
    "    the form:\n",
    "\n",
    "    .. math::\n",
    "        \\log{L(\\theta, \\sigma|\\boldsymbol{x})} =\n",
    "            N\\frac{4}{2}\\log(4) - N\\log(\\sigma\\sqrt{f(\\theta)}) -\n",
    "            N\\log B(4/2, 1/2)\n",
    "            -\\frac{1+4}{2}\\sum_{i=1}^N\\log(4 +\n",
    "            \\frac{x_i - f(\\theta)}{\\sigma\\sqrt{f(\\theta)}}^2)\n",
    "\n",
    "    where ``B(.,.)`` is a beta function.\n",
    "\n",
    "    Extends :class:`ProblemLogLikelihood`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem\n",
    "        A :class:`SingleOutputProblem` or :class:`MultiOutputProblem`. For a\n",
    "        single-output problem one parameter is added ``(sigma)``, where\n",
    "        ``sigma`` is scale, for a multi-output problem ``n_outputs`` parameters are added.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, problem):\n",
    "        super(StudentTLogLikelihoodMultiplicative4, self).__init__(problem)\n",
    "\n",
    "        # Get number of times, number of outputs\n",
    "        self._nt = len(self._times)\n",
    "        self._no = problem.n_outputs()\n",
    "\n",
    "        # Add parameters to problem (two for each output)\n",
    "        self._n_parameters = problem.n_parameters() + self._no\n",
    "\n",
    "        # Pre-calculate\n",
    "        self._n = len(self._times)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # For multiparameter problems the parameters are stored as\n",
    "        # (model_params_1, model_params_2, ..., model_params_k,\n",
    "        # nu_1, sigma_1, nu_2, sigma_2,...)\n",
    "        n = self._n\n",
    "        m = self._no\n",
    "\n",
    "        # problem parameters\n",
    "        problem_parameters = x[:-m]\n",
    "        y = self._problem.evaluate(problem_parameters)\n",
    "        error = self._values - y\n",
    "\n",
    "        # Distribution parameters\n",
    "        parameters = x[-m:]\n",
    "        sigma = np.asarray(parameters[0::2])\n",
    "        nu = np.repeat(4, m)\n",
    "\n",
    "        # Calculate\n",
    "        return np.sum(\n",
    "            + 0.5 * n * nu * np.log(nu)\n",
    "            - n * np.log(sigma * np.sqrt(y))\n",
    "            - n * np.log(scipy.special.beta(0.5 * nu, 0.5))\n",
    "            - 0.5 * (1 + nu) * np.sum(np.log(nu + (error / (sigma * sqrt(y)))**2), axis=0)\n",
    "        )\n",
    "    \n",
    "likelhood = StudentTLogLikelihoodMultiplicative4(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the prior distribution for each of the parameters to be estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lamda_prior = pints.LogNormalLogPrior(math.log10(0.4),0.5) # lamda has Log-Normal prior\n",
    "mu_prior = pints.LogNormalLogPrior(math.log10(1/8),0.2) # mu has Log-Normal prior\n",
    "delay_prior = pints.LogNormalLogPrior(math.log10(8),0.2) # D has Log-Normal prior\n",
    "initInfected_prior = pints.HalfCauchyLogPrior(0,100) # I0 has Half-Cauchy prior\n",
    "scaleWidth_prior = pints.HalfCauchyLogPrior(0,10) # sigma has Half-Cauchy prior\n",
    "fw_prior = pints.BetaLogPrior(0.7, 0.17) # f_w has Beta prior\n",
    "phi_prior = vonmises.pdf(0,0.01) # phi_w has Von Mises prior\n",
    "\n",
    "log_priors = [lamda_prior, mu_prior, delay_prior, initInfected_prior, scaleWidth_prior, fw_prior, phi_prior]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the posterior distribution, \\\\(p(\\theta|\\hat C )\\\\), below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "posterior = pints.LogPosterior(likelihood, log_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the MCMC sampling scheme, using the adaptive covariance method (Haario-Bardenet). According to the paper, we need to create 4 chains, perform 1000 burn-in steps, and sample for 4000 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "startingParamVals = [initLam, initMu, initDelay, initInfected, initScale, initFw, initPhi]\n",
    "\n",
    "xs = [\n",
    "    startingParamVals * 1.1,\n",
    "    startingParamVals * 1.05,\n",
    "    startingParamVals * 0.9,\n",
    "    startingParamVals * 1.15,\n",
    "]\n",
    "\n",
    "# Create mcmc routine with four chains\n",
    "mcmc = pints.MCMCController(posterior, 4, xs, method=pints.HaarioBardenetACMC)\n",
    "\n",
    "# Add stopping criterion\n",
    "mcmc.set_max_iterations(4000)\n",
    "\n",
    "# Start adapting after 1000 iterations\n",
    "mcmc.set_initial_phase_iterations(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
